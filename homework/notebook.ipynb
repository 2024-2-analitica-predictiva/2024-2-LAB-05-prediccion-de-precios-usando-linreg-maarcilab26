{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1.\n",
    "# Preprocese los datos.\n",
    "# - Cree la columna 'Age' a partir de la columna 'Year'.\n",
    "#   Asuma que el año actual es 2021.\n",
    "# - Elimine las columnas 'Year' y 'Car_Name'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Selling_Price</th>\n",
       "      <th>Present_Price</th>\n",
       "      <th>Driven_kms</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Selling_type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.75</td>\n",
       "      <td>9.54</td>\n",
       "      <td>43000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.25</td>\n",
       "      <td>9.85</td>\n",
       "      <td>6900</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.85</td>\n",
       "      <td>4.15</td>\n",
       "      <td>5200</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.75</td>\n",
       "      <td>8.12</td>\n",
       "      <td>18796</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.50</td>\n",
       "      <td>8.61</td>\n",
       "      <td>33429</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Selling_Price  Present_Price  Driven_kms Fuel_Type Selling_type  \\\n",
       "0           4.75           9.54       43000    Diesel       Dealer   \n",
       "1           7.25           9.85        6900    Petrol       Dealer   \n",
       "2           2.85           4.15        5200    Petrol       Dealer   \n",
       "3           6.75           8.12       18796    Petrol       Dealer   \n",
       "4           6.50           8.61       33429    Diesel       Dealer   \n",
       "\n",
       "  Transmission  Owner  Age  \n",
       "0       Manual      0    8  \n",
       "1       Manual      0    4  \n",
       "2       Manual      0   10  \n",
       "3       Manual      0    6  \n",
       "4       Manual      0    6  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Cargar los archivos\n",
    "train_data = pd.read_csv(\"../files/input/train_data.csv.zip\", compression =\"zip\",)\n",
    "#train_data.head()\n",
    "test_data = pd.read_csv(\"../files/input/test_data.csv.zip\", compression=\"zip\",)\n",
    "#test_data.head()\n",
    "\n",
    "#Procesamiento de los datos\n",
    "def transformar_data(data):\n",
    "    data[\"Age\"] = 2021 - data[\"Year\"]\n",
    "    data = data.drop([\"Year\",\"Car_Name\"], axis=1) # axis=1 indica que se está eliminando columnas\n",
    "    return data\n",
    "\n",
    "#Aplicar la función\n",
    "train_data = transformar_data(train_data)\n",
    "test_data = transformar_data(test_data)\n",
    "\n",
    "#Revisar resultados\n",
    "train_data.head()\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2.\n",
    "# Divida los datasets en x_train, y_train, x_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos divididos:\n",
      "X_train: (211, 7), y_train: (211,)\n",
      "X_test: (90, 7), y_test: (90,)\n"
     ]
    }
   ],
   "source": [
    "# Crear copias de los datasets originales para trabajar\n",
    "train_data_copy = train_data.copy()\n",
    "test_data_copy = test_data.copy()\n",
    "\n",
    "# Dividir los datos en X (características) e y (variable objetivo)\n",
    "# Para el dataset de entrenamiento\n",
    "X_train = train_data_copy.drop(columns=[\"Present_Price\"])  # Todas las columnas excepto la columna objetivo\n",
    "y_train = train_data_copy[\"Present_Price\"]  # Solo la columna objetivo\n",
    "\n",
    "# Para el dataset de prueba\n",
    "X_test = test_data_copy.drop(columns=[\"Present_Price\"])  # Todas las columnas excepto la columna objetivo\n",
    "y_test = test_data_copy[\"Present_Price\"]  # Solo la columna objetivo\n",
    "\n",
    "print(\"Datos divididos:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3.\n",
    "# Cree un pipeline para el modelo de clasificación. Este pipeline debe\n",
    "# contener las siguientes capas:\n",
    "# - Transforma las variables categoricas usando el método\n",
    "#   one-hot-encoding.\n",
    "# - Escala las variables numéricas al intervalo [0, 1].\n",
    "# - Selecciona las K mejores entradas.\n",
    "# - Ajusta un modelo de regresion lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline creado con éxito:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Paso 1: Identificar variables categóricas y numéricas\n",
    "categorical_columns = [\"Fuel_Type\", \"Selling_type\", \"Transmission\"]\n",
    "numeric_columns = [col for col in X_train.columns if col not in categorical_columns]\n",
    "\n",
    "# Paso 2: Transformaciones para cada tipo de variable\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')  # One-hot encoding\n",
    "numerical_transformer = MinMaxScaler()  # Escalado al rango [0, 1]\n",
    "\n",
    "# Paso 3: Crear un preprocesador para transformar variables categóricas y numéricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numeric_columns),  # Transformar numéricas\n",
    "        ('cat', categorical_transformer, categorical_columns)  # Transformar categóricas\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Paso 4: Construir el pipeline completo\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),  # Transformaciones iniciales\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression)),  # Seleccionar las K mejores características\n",
    "    ('model', LinearRegression())  # Modelo de regresión lineal\n",
    "])\n",
    "\n",
    "print(\"Pipeline creado con éxito:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4.\n",
    "# Optimice los hiperparametros del pipeline usando validación cruzada.\n",
    "# Use 10 splits para la validación cruzada. Use el error medio absoluto\n",
    "# para medir el desempeño modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "Mejores hiperparámetros: {'feature_selection__k': 11, 'model__fit_intercept': False}\n",
      "Mejor MAE obtenido: 1.7810\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "# Definir los hiperparámetros a optimizar\n",
    "param_grid = {\n",
    "    'feature_selection__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12],  # Diferentes valores para el número de características a seleccionar\n",
    "    'model__fit_intercept': [True,False],  # Ajustar o no el intercepto\n",
    "}\n",
    "\n",
    "# Crear un objeto para medir el error medio absoluto\n",
    "#mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Configurar la búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,                # El pipeline a optimizar\n",
    "    param_grid=param_grid,             # Espacio de búsqueda de hiperparámetros\n",
    "    scoring='neg_mean_absolute_error',                # Métrica de desempeño (MAE)\n",
    "    cv=10,                             # Número de particiones para validación cruzada\n",
    "    n_jobs=-1,                         # Usar todos los núcleos disponibles\n",
    "    verbose=1                          # Mostrar progreso detallado\n",
    ")\n",
    "\n",
    "# Ajustar la búsqueda de hiperparámetros a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros y el mejor desempeño\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(f\"Mejor MAE obtenido: {-grid_search.best_score_:.4f}\")  # Cambiar a positivo\n",
    "\n",
    "# Actualizar el pipeline con los mejores parámetros encontrados\n",
    "best_pipeline = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5.\n",
    "# Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    "# Recuerde que es posible guardar el modelo comprimido usanzo la libreria gzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado exitosamente en ../files/models/model.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Definir la ruta del directorio y archivo\n",
    "dir_path = '../files/models'\n",
    "model_path = '../files/models/model.pkl.gz'\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Guardar el objeto `grid_search.best_estimator_` comprimido con gzip\n",
    "with gzip.open(model_path, 'wb') as f:\n",
    "    pickle.dump(grid_search, f)\n",
    "\n",
    "print(f\"Modelo guardado exitosamente en {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 6.\n",
    "# Calcule las metricas r2, error cuadratico medio, y error absoluto medio\n",
    "# para los conjuntos de entrenamiento y prueba. Guardelas en el archivo\n",
    "# files/output/metrics.json. Cada fila del archivo es un diccionario con\n",
    "# las metricas de un modelo. Este diccionario tiene un campo para indicar\n",
    "# si es el conjunto de entrenamiento o prueba. Por ejemplo:\n",
    "#\n",
    "# {'type': 'metrics', 'dataset': 'train', 'r2': 0.8, 'mse': 0.7, 'mad': 0.9}\n",
    "# {'type': 'metrics', 'dataset': 'test', 'r2': 0.7, 'mse': 0.6, 'mad': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas guardadas exitosamente en ../files/output\\metrics.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score\n",
    "\n",
    "# Asegurarnos de usar el mejor modelo encontrado\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones\n",
    "y_train_pred = final_model.predict(X_train)\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas para el conjunto de entrenamiento\n",
    "train_metrics = {\n",
    "    \"type\": \"metrics\",\n",
    "    'dataset': 'train',\n",
    "    'r2': r2_score(y_train, y_train_pred),\n",
    "    'mse': mean_squared_error(y_train, y_train_pred),\n",
    "    'mad': median_absolute_error(y_train, y_train_pred)\n",
    "}\n",
    "\n",
    "# Calcular métricas para el conjunto de prueba\n",
    "test_metrics = {\n",
    "    \"type\": \"metrics\",\n",
    "    'dataset': 'test',\n",
    "    'r2': r2_score(y_test, y_test_pred),\n",
    "    'mse': mean_squared_error(y_test, y_test_pred),\n",
    "    'mad': median_absolute_error(y_test, y_test_pred)\n",
    "}\n",
    "\n",
    "# Definir la ruta del archivo de salida\n",
    "output_dir = \"../files/output\"\n",
    "output_path = os.path.join(output_dir, \"metrics.json\")\n",
    "\n",
    "# Crear las carpetas necesarias si no existen\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Guardar las métricas en un archivo JSON\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(train_metrics, f)  # Guardar las métricas de entrenamiento\n",
    "    f.write(\"\\n\")  # Escribir una nueva línea\n",
    "    json.dump(test_metrics, f)  # Guardar las métricas de prueba\n",
    "\n",
    "print(f\"Métricas guardadas exitosamente en {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
